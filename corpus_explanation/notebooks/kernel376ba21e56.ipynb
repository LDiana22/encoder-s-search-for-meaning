{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport torch\ntorch.manual_seed(0)\nCONFIG = {\n    \"toy_data\": False, # load only a small subset\n\n    \"cuda\": True,\n\n    \"embedding\": \"glove\",\n\n    \"restore_checkpoint\" : False,\n    \"checkpoint_file\": None,\n    \"train\": True,\n\n    \"dropout\": 0.05,\n    \"weight_decay\": 5e-06,\n\n    \"patience\": 5,\n\n    \"epochs\": 12,\n\n    \"objective\": \"cross_entropy\",\n    \"init_lr\": 0.0001,\n\n    \"gumbel_decay\": 1e-5,\n\n\n    \"max_words_dict\": 5,\n\n\n    \"prefix_dir\" : \"experiments\",\n    \n    \"dirs\": {\n        \"metrics\": \"metrics\",\n        \"checkpoint\": \"snapshot\",\n        \"dictionary\": \"dictionaries\"\n        },\n\n    \"aspect\": \"palate\", # aroma, palate, smell, all\n    \"max_vocab_size\": 25000,\n    \"emb_dim\": 300,\n    \"batch_size\": 32,\n    \"output_dim\": 1,\n}\n\nMODEL_MAPPING = \"experiments/models_mappings\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATE_FORMAT = '%Y-%m-%d_%H-%M-%S'\nDATE_REGEXP = '[0-9]{4}-[0-9]{2}-[0-9]{2}_[0-9]{2}-[0-9]{2}-[0-9]{2}'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport re\n\nfrom datetime import datetime\n\ndef _extract_date(f):\n  date_string = re.search(f\"^{ct.DATE_REGEXP}\",f)[0]\n  return datetime.strptime(date_string, ct.DATE_FORMAT)\n\ndef get_max_index_checkpoint(path):\n  \"\"\"\n  Return int: suffix of checkpoint name\n  \"\"\"\n  list_of_files = os.listdir(path)\n  # list_of_files = [\"checkpoint_1\",\"checkpoint_10\",\"checkpoint_2\", \"checkpoint_22\"]\n\n  n = max([_extract_number(f) for f in list_of_files]) if list_of_files else None\n  if n is None:\n    return 0\n\n  return n\n\ndef get_last_checkpoint_by_date(path):\n  \"\"\"\n  Return file_name with the largest suffix number\n  \"\"\"\n  list_of_files = os.listdir(path)\n\n  file_dates = {_extract_date(f): f for f in list_of_files}\n  if file_dates:\n    key = sorted(file_dates.keys(), reverse=True)[0]\n    return file_dates[key]\n  else:\n    return None\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experiment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport torch\nimport time\nfrom datetime import datetime\nimport os\nfrom tqdm import tqdm\n\nclass Experiment(object):\n  \"\"\"Holds all the experiment parameters and provides helper functions.\"\"\"\n  def __init__(self, e_id):\n    self.id = e_id\n      \n  def restore_model(self):\n    if self.config[\"restore_checkpoint\"]:\n      checkpoint = self.model.checkpoint_dir\n      if self.config[\"checkpoint_file\"] is None:\n        last_checkpoint = get_last_checkpoint_by_date(checkpoint)\n      else:\n        last_checkpoint = self.config[\"checkpoint_file\"]\n      if last_checkpoint is not None:\n        self.model.load_checkpoint(last_checkpoint)\n        return True  \n      else:\n        print(f\"No checkpoint found at {checkpoint}\")\n    return False\n\n  def setup(self):\n      self.restore_model()\n      return self\n              \n\n  ### DECLARATIVE API ###\n\n  def with_data(self, data):\n      self.data = data\n      return self\n\n  def with_dictionary(self, dictionary):\n      self.dictionary = dictionary\n      return self\n\n  def with_config(self, config):\n      self.config = config.copy()\n      return self\n\n  def override(self, config):\n      self.config.update(config)\n      return self\n\n  def with_model(self, model):\n      self.model = model\n      return self\n  #### END API ######\n  \n  @property\n  def experiment_name(self):\n      return f'E-{self.id}_M-{self.model.id}'\n\n  \"\"\" Dirs\n  - *_dir - full path to dir\n  \"\"\"\n  @property\n  def experiments_dir(self):\n      return \"experiments\"\n\n  def train_model(self):\n    training_start_time = datetime.now()\n\n    training_losses, training_acc = [], []\n    v_losses, v_acc = [], []\n\n    best_valid_loss = float('inf')\n    n_epochs = self.config[\"epochs\"]\n    for epoch in tqdm(range(n_epochs)):\n      start_time = datetime.now()\n\n      train_metrics = self.model.train_model(self.train_iterator)\n      valid_metrics = self.model.evaluate(self.valid_iterator, \"valid\")\n      \n      end_time = datetime.now()\n      \n      training_losses.append(train_metrics[\"train_loss\"])\n      training_acc.append(train_metrics[\"train_acc\"])\n      v_losses.append(valid_metrics[\"valid_loss\"])\n      v_acc.append(valid_metrics[\"valid_acc\"])\n\n      if valid_metrics[\"valid_loss\"] < best_valid_loss:\n        best_valid_loss = valid_metrics[\"valid_loss\"]\n        metrics = train_metrics\n        metrics.update(valid_metrics)\n        self.model.checkpoint(epoch, metrics)\n    \n      print(f'Epoch: {epoch+1:02} | Epoch Time: {str(end_time-start_time)}')\n      print(f'\\tTrain Loss: {train_metrics[\"train_loss\"]:.3f} | Train Acc: {train_metrics[\"train_acc\"]*100:.2f}%')\n      print(f'\\t Val. Loss: {valid_metrics[\"valid_loss\"]:.3f} |  Val. Acc: {valid_metrics[\"valid_acc\"]*100:.2f}%')\n\n    \n    print(f'Training Time: {str(datetime.now()-training_start_time)}')\n    print(f'Training losses: {training_losses}')\n    print(f'Training acc: {training_acc}')\n    print(f'Valid losses: {v_losses}')\n    print(f'Valid acc: {v_acc}')\n\n  def run(self):\n      if self.config[\"restore_checkpoint\"]:\n        loaded = self.restore_model()\n        if not loaded:\n          return\n      self.train_iterator, self.valid_iterator, self.test_iterator = self.data.iterators()\n      if self.config[\"train\"]:\n        print(\"Training...\")\n        self.train_model()\n      print(\"Evaluating...\")\n      metrics = self.model.evaluate(self.test_iterator)\n      self.model.save_results(metrics)\n      \n      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchtext.data import Pipeline\nimport re\n\ndef remove_br_tag(token):\n    return re.sub(r\"br|(/><.*)|(</?(.*)/?>)|(<?(.*)/?>)|(<?/?(.*?)/?>?)\", \"\", token)\n\nremove_br_html_tags = Pipeline(remove_br_tag)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport os\nimport io\nimport random\nimport re\nimport spacy\nfrom torchtext import datasets\nfrom torchtext import data as data\nfrom torchtext.vocab import GloVe\nimport torch\n\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = True\n\nclass IMDBDataset:\n\n  def __init__(self, args, max_length=250):\n    self.args = args\n    self.max_sent_len = 800\n    TEXT = data.Field(lower=True, \n                      include_lengths=True,\n                      tokenize='spacy',\n                      preprocessing=remove_br_html_tags)\n    LABEL = data.LabelField(dtype = torch.float)\n    print(\"Loading the IMDB dataset...\")\n    self.train_data = self._load_data(TEXT, LABEL, \"/kaggle/input/aclimdb/aclImdb\", \"train\")\n    self.test_data = self._load_data(TEXT, LABEL, \"/kaggle/input/aclimdb/aclImdb\", \"test\")\n#     self.train_data, self.test_data =  datasets.IMDB.splits(TEXT, LABEL)\n    self.train_data, self.valid_data = self.train_data.split(random_state=random.seed(0))\n    print(\"IMDB...\")\n    print(f\"Train {len(self.train_data)}\")\n    print(f\"Valid {len(self.valid_data)}\")\n    print(f\"Test {len(self.test_data)}\")\n    TEXT.build_vocab(self.train_data, \n                 max_size = args[\"max_vocab_size\"],\n                 vectors = GloVe(name='6B', dim=args[\"emb_dim\"]), \n                 unk_init = torch.Tensor.normal_)\n\n\n    LABEL.build_vocab(self.train_data)\n\n    self.TEXT = TEXT\n    self.device = torch.device('cuda' if args[\"cuda\"] else 'cpu')\n\n  def _load_data(self, text_field, label_field, path, data_type=\"train\"):\n    fields = [('text', text_field), ('label', label_field)]\n    examples = []\n    path = os.path.join(path, data_type)\n    for label in ['pos', 'neg']:\n      print(f\"{os.path.join(path, label, f'{label}.txt')}\")\n      fname = os.path.join(path, label, f'{label}.txt')\n      with io.open(fname, 'r', encoding='utf-8', errors='replace') as f:\n        for text in f:\n          if text != '\\n':\n            sent_len = len(text.split())\n            if sent_len > self.max_sent_len:\n              self.max_sent_len = sent_len\n            examples.append(data.Example.fromlist([text, label], fields))\n          if self.args[\"toy_data\"] and (len(examples)==50 or len(examples)==100):\n            break\n\n    print(f'Loaded {len(examples)}')\n    fields = dict(fields)\n    # Unpack field tuples\n    for n, f in list(fields.items()):\n      if isinstance(n, tuple):\n        fields.update(zip(n, f))\n        del fields[n]\n    return data.Dataset(examples, fields)\n\n  def iterators(self):\n    \"\"\"\n      Returns train_iterator, valid_iterator, test_iterator\n    \"\"\"\n    return data.BucketIterator.splits(\n      (self.train_data, self.valid_data, self.test_data), \n      batch_size = self.args[\"batch_size\"],\n      sort_within_batch = True,\n      sort_key=lambda x: len(x.text),\n      device = self.device)\n\n  def training(self):\n    return self.training_data\n\n  def get_training_corpus(self):\n    self.corpus = {\"pos\":[], \"neg\":[]}\n    self.corpus[\"pos\"] = [\" \".join(example.text) for example in self.train_data if example.label == \"pos\"]\n    self.corpus[\"neg\"] = [\" \".join(example.text) for example in self.train_data if example.label == \"neg\"]\n    return self.corpus\n\n  def dev(self):\n    return self.valid_data\n\n  def test(self):\n    return self.test_data \n\n  def override(self, args):\n    self.args.update(args)\n    return selfi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dictionary"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pickle\n\nclass AbstractDictionary:\n  def __init__(self, id, dataset, args):\n    \"\"\"\n    A dictionary consists of a list of entries per each class.\n    For a corpus dictionary, there is only one \"dummy class\" considered.\n    \"\"\"\n    self.id = id\n    self.dataset = dataset\n    self.args = args \n    self.path = os.path.join(self.args[\"prefix_dir\"], self.args[\"dirs\"][\"dictionary\"], id)\n    self.metrics = {}\n\n  def _save_dict(self):\n    if not os.path.isdir(self.path):\n      os.makedirs(self.path)\n    file = os.path.join(self.path, \"dictionary.h5\")\n    with open(file, \"wb\") as f: \n      f.write(pickle.dumps(self.dictionary))\n\n    file = os.path.join(self.path, \"dictionary.txt\")\n    with open(file, \"w\", encoding=\"utf-8\") as f:\n      f.write(str(self.dictionary))\n\n    self.print_metrics()\n\n  def _compute_metrics(self):\n    overlap = 0 # number of overlapped entries for each label\n    global_avg_w = 0 # global average words per instance\n    global_count = 0\n    class_avg_w = {}\n    word_intersection = None\n    for class_label in self.dictionary.keys():\n      instances = list(self.dictionary[class_label].keys())\n      no_instances = len(instances)\n      if word_intersection is None:\n        word_intersection = set(instances)\n      else:\n        word_intersection = set(instances).intersection(word_intersection)\n        overlap = len(word_intersection)\n      sum_number_of_words = sum([len(instance.split(\" \")) for instance in instances])\n      class_avg_w[class_label] = sum_number_of_words/no_instances\n      global_avg_w += sum_number_of_words\n      global_count += no_instances\n    if global_count:\n      global_avg_w = global_avg_w/global_count\n    self.metrics = {\n      \"dictionary_entries\": global_count,\n      \"overlap_count\": overlap,\n      \"global_average_words_per_instance\": global_avg_w,\n      \"class_average\": class_avg_w,\n      \"overlap_words\": word_intersection\n    }\n\n  def print_metrics(self):\n    if not self.metrics:\n      self._compute_metrics()\n    metrics_path = os.path.join(self.path, \"metrics.txt\")\n    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n      f.write(str(self.metrics))\n\n  def get_dict(self):\n    \"\"\"\n    Abstract method for building the dictionary\n    \"\"\"\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install rake_nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nimport os\nfrom rake_nltk import Rake\n\nimport spacy\n\nclass RakePerClassExplanations(AbstractDictionary):\n\n  def __init__(self, id, dataset, args): \n    super().__init__(id, dataset, args)\n    self.max_dict = args.get(\"max_dict\", None)\n    self.max_words = args[\"max_words_dict\"]\n    self.rake = Rake() # Uses stopwords for english from NLTK, and all puntuation characters.\n    self.dictionary = self.get_dict()\n    self.tokenizer = spacy.load(\"en\")\n    self._save_dict()\n\n  def get_dict(self):\n    \"\"\"\n    Builds a dictionary of keywords for each label.\n    # {\"all\":{word:freq}} OR\n    {\"pos\":{word:freq}, \"neg\":{word:freq}}\n    \"\"\"\n    if hasattr(self, 'dictionary') and not self.dictionary:\n      return self.dictionary\n    dictionary = {} \n    corpus = self.dataset.get_training_corpus()\n\n    max_per_class = int(self.max_dict / len(corpus.keys())) if self.max_dict else None\n    for text_class in corpus.keys():\n      dictionary[text_class] = {}\n      class_corpus = \" \".join(corpus[text_class])\n      self.rake.extract_keywords_from_text(class_corpus)\n      phrases = self.rake.get_ranked_phrases()[:max_per_class]\n      if max_per_class:\n        phrases = phrases[:max_per_class]\n      # get word freq\n      # tok_words = self.tokenizer(class_corpus)\n      # word_freq = Counter([token.text for token in tok_words if not token.is_punct])\n      # build dict\n      for phrase in phrases:\n        # trim phrase to max words\n        phrase = \" \".join(phrase.split()[:self.max_words])\n        dictionary[text_class][phrase] = class_corpus.count(phrase)\n\n    return dictionary\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from abc import ABC\nimport os.path\nfrom datetime import datetime\nimport torch\nfrom contextlib import redirect_stdout\nfrom torch import nn\nfrom datetime import datetime\n\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nclass AbstractModel(nn.Module):\n    \"\"\"\n    Abstract Model\n        - saves the mapping between the model-id and its parameters and\n            model summary\n        - creates the directories for the log files\n    \"\"\"\n    def __init__(self, id, mapping_file_location, model_args):\n        \"\"\"\n        id: Model id\n        mapping_file_location: directory to store the file \"model_id\" \n                               that containes the hyperparameters values and \n                               the model summary\n        logs_location: directory for the logs location of the model\n        model_args: hyperparameters of the model\n        \"\"\"\n        super().__init__()\n        self.delim = \"#################################\"\n        self.id = id\n        self.mapping_location = mapping_file_location\n        self.args = model_args\n        self.device = torch.device('cuda' if model_args[\"cuda\"] else 'cpu')\n        self.model_dir = model_dir = os.path.join(self.args[\"prefix_dir\"], self.id)\n        self.__create_directories()\n\n    def override(self, args):\n        self.args.update(args)\n\n    def __create_directories(self):\n        \"\"\"\n        All the directories for a model are placed under the directory \n            prefix_dir / model_id / {dirs}\n        \"\"\" \n        self.checkpoint_dir = os.path.join(self.model_dir, self.args[\"dirs\"][\"checkpoint\"])\n        for directory in self.args[\"dirs\"].values():\n            m_dir = os.path.join(self.model_dir, directory)\n            if not os.path.isdir(m_dir):\n                os.makedirs(m_dir)\n        if not os.path.isdir(self.mapping_location):\n            os.makedirs(self.mapping_location)\n\n    def save_model_type(self, model):\n        \"\"\"\n        Saves the hyperparameters \n        \"\"\"\n        mapping_file = os.path.join(self.mapping_location, self.id)        \n        with open(mapping_file, \"w\") as map_file:\n            print(self.delim, file=map_file)\n            print(self.args, file=map_file)\n            print(self.delim, file=map_file)\n            print(self, file=map_file)\n            print(self.delim, file=map_file)\n\n    def checkpoint(self, epoch, metrics):\n        checkpoint_file = os.path.join(self.checkpoint_dir, \n            f'{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_e{epoch}')\n        self.dict_checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': self.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            }\n        self.dict_checkpoint.update(metrics)\n        torch.save(self.dict_checkpoint, checkpoint_file)\n\n    def load_checkpoint(self, newest_file_name):\n        checkpoint_dir = os.path.join(self.model_dir, self.args[\"dirs\"][\"checkpoint\"])           \n\n        path = os.path.join(checkpoint_dir, newest_file_name)\n        print(f\"Loading checkpoint: {path}\") \n        checkpoint = torch.load(path)\n        self.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.epoch = checkpoint['epoch']\n        self.metrics = {}\n        for key in checkpoint.keys():\n            if key not in ['epoch', 'model_state_dict', 'optimizer_state_dict']:\n                self.metrics[key] = checkpoint[key]\n\n    def save_results(self, metrics):\n        metrics_path = os.path.join(self.model_dir, self.args[\"dirs\"][\"metrics\"])\n        results_file = os.path.join(metrics_path, f\"results_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n        with open(results_file, \"w\") as f:\n            f.write(str(metrics))\n\n    # def train_model(self, iterator):\n    #     \"\"\"\n    #     Abstract method, avoiding multiple inheritance\n    #     Return a metrics dict with the keys prefixed by 'train'\n    #     e.g. metrics={\"train_acc\": 90.0, \"train_loss\": 0.002}\n    #     \"\"\"\n    #     pass\n\n    # def evaluate(self, iterator, prefix=\"test\"):\n    #     \"\"\"\n    #     Abstract method, avoiding multiple inheritance\n\n    #     Return a metrics dict with the keys prefixed by prefix\n    #     e.g. metrics={f\"{prefix}_acc\": 90.0, f\"{prefix}_loss\": 0.002}\n    #     \"\"\"\n    #     pass\n\n\n    def train_model(self, iterator):\n        \"\"\"\n        metrics.keys(): [train_acc, train_loss, train_prec,\n                        train_rec, train_f1, train_macrof1,\n                        train_microf1, train_weightedf1]\n        \"\"\"\n        e_loss = 0\n        e_acc, e_prec, e_rec = 0,0,0\n        e_f1, e_macrof1, e_microf1, e_wf1 = 0,0,0,0\n\n        self.train()\n\n        for batch in iterator:\n            self.optimizer.zero_grad()\n            text, text_lengths = batch.text\n            logits = self.forward(text, text_lengths).squeeze()\n            batch.label = batch.label.to(self.device)\n            loss = self.criterion(logits, batch.label)\n\n            y_pred = torch.round(torch.sigmoid(logits)).detach().cpu().numpy()\n            y_true = batch.label.cpu().numpy()\n            #metrics\n            acc = accuracy_score(y_true, y_pred)\n            prec = precision_score(y_true, y_pred)\n            rec = recall_score(y_true, y_pred)\n            f1 = f1_score(y_true, y_pred)\n            macrof1 = f1_score(y_true, y_pred, average='macro')\n            microf1 = f1_score(y_true, y_pred, average='micro')\n            wf1 = f1_score(y_true, y_pred, average='weighted')\n\n            loss.backward()\n            self.optimizer.step()\n\n            e_loss += loss.item()\n            e_acc += acc\n            e_prec += prec\n            e_rec += rec\n            e_f1 += f1\n            e_macrof1 += macrof1\n            e_microf1 += microf1\n            e_wf1 += wf1\n        \n        metrics ={}\n        size = len(iterator)\n        metrics[\"train_loss\"] = e_loss/size\n        metrics[\"train_acc\"] = e_acc/size\n        metrics[\"train_prec\"] = e_prec/size\n        metrics[\"train_rec\"] = e_rec/size\n        metrics[\"train_f1\"] = e_f1/size\n        metrics[\"train_macrof1\"] = e_macrof1/size\n        metrics[\"train_microf1\"] = e_microf1/size\n        metrics[\"train_weightedf1\"] = e_wf1/size\n\n        return metrics\n\n    def evaluate(self, iterator, prefix=\"test\"):\n        \"\"\"\n            Return a metrics dict with the keys prefixed by prefix\n            metrics = {}\n        \"\"\"\n        self.eval()\n\n        e_loss = 0\n        e_acc, e_prec, e_rec = 0,0,0\n        e_f1, e_macrof1, e_microf1, e_wf1 = 0,0,0,0\n        with torch.no_grad():\n            for batch in iterator:\n                text, text_lengths = batch.text\n                logits = self.forward(text, text_lengths).squeeze()\n                batch.label = batch.label.to(self.device)\n                loss = self.criterion(logits, batch.label)\n    \n                predictions = torch.round(torch.sigmoid(logits))\n\n                y_pred = predictions.detach().cpu().numpy()\n                y_true = batch.label.cpu().numpy()\n                \n                acc = accuracy_score(y_true, y_pred)\n                prec = precision_score(y_true, y_pred)\n                rec = recall_score(y_true, y_pred)\n                f1 = f1_score(y_true, y_pred)\n                macrof1 = f1_score(y_true, y_pred, average='macro')\n                microf1 = f1_score(y_true, y_pred, average='micro')\n                wf1 = f1_score(y_true, y_pred, average='weighted')\n\n                e_loss += loss.item()\n                e_acc += acc\n                e_prec += prec\n                e_rec += rec\n                e_f1 += f1\n                e_macrof1 += macrof1\n                e_microf1 += microf1\n                e_wf1 += wf1\n\n        metrics ={}\n        size = len(iterator)\n        metrics[f\"{prefix}_loss\"] = e_loss/size\n        metrics[f\"{prefix}_acc\"] = e_acc/size\n        metrics[f\"{prefix}_prec\"] = e_prec/size\n        metrics[f\"{prefix}_rec\"] = e_rec/size\n        metrics[f\"{prefix}_f1\"] = e_f1/size\n        metrics[f\"{prefix}_macrof1\"] = e_macrof1/size\n        metrics[f\"{prefix}_microf1\"] = e_microf1/size\n        metrics[f\"{prefix}_weightedf1\"] = e_wf1/size\n        return metrics\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.optim as optim\n\nclass VLSTM(AbstractModel):\n    \"\"\"\n    Baseline - no generator model\n    \"\"\"\n    def __init__(self, id, mapping_file_location, model_args, TEXT):\n        \"\"\"\n        id: Model id\n        mapping_file_location: directory to store the file \"model_id\" \n                               that containes the hyperparameters values and \n                               the model summary\n        logs_location: directory for the logs location of the model\n        model_args: hyperparameters of the model\n        \"\"\"\n        super().__init__(id, mapping_file_location, model_args)\n        self.device = torch.device('cuda' if model_args[\"cuda\"] else 'cpu')\n        \n        UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n        PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n        self.input_size = len(TEXT.vocab)\n        self.embedding = nn.Embedding(self.input_size, model_args[\"emb_dim\"], padding_idx=PAD_IDX)\n        self.embedding.weight.data.copy_(TEXT.vocab.vectors)\n        self.embedding.weight.data[UNK_IDX] = torch.zeros(model_args[\"emb_dim\"])\n        self.embedding.weight.data[PAD_IDX] = torch.zeros(model_args[\"emb_dim\"])\n\n        self.lstm = nn.LSTM(model_args[\"emb_dim\"], \n                           model_args[\"hidden_dim\"], \n                           num_layers=model_args[\"n_layers\"], \n                           bidirectional=True, \n                           dropout=model_args[\"dropout\"])\n        self.lin = nn.Linear(2*model_args[\"hidden_dim\"], model_args[\"output_dim\"]).to(self.device)\n        self.dropout = nn.Dropout(model_args[\"dropout\"])\n        \n        self.optimizer = optim.Adam(self.parameters())\n        self.criterion = nn.BCEWithLogitsLoss().to(self.device)\n\n        self = self.to(self.device)\n        super().save_model_type(self)\n\n    def forward(self, text, text_lengths):\n        text = text.to(self.device)\n        #text = [sent len, batch size]\n        embedded = self.dropout(self.embedding(text))\n        \n        #embedded = [sent len, batch size, emb dim]\n        \n        return self.raw_forward(embedded, text_lengths)\n\n    def raw_forward(self, embedded, text_lengths):\n\n        #pack sequence\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n        \n        #unpack sequence\n        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n\n        #output = [sent len, batch size, hid dim * num directions]\n        #output over padding tokens are zero tensors\n        \n        #hidden = [num layers * num directions, batch size, hid dim]\n        #cell = [num layers * num directions, batch size, hid dim]\n        \n        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n        #and apply dropout\n        \n        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n                \n        #hidden = [batch size, hid dim * num directions]\n            \n        return self.lin(hidden).to(self.device)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport torch\nfrom torch import nn\nimport torch.optim as optim\n\nclass MLPGen(AbstractModel):\n    \"\"\"\n    MLP generator - dictionary for all classes (mixed)\n    \"\"\"\n    def __init__(self, id, mapping_file_location, model_args, dataset, explanations):\n        \"\"\"\n        id: Model id\n        mapping_file_location: directory to store the file \"model_id\" \n                               that containes the hyperparameters values and \n                               the model summary\n        logs_location: directory for the logs location of the model\n        model_args: hyperparameters of the model\n        explanations: Dictionary of explanations [{phrase: {class:freq}}]\n        \"\"\"\n        super().__init__(id, mapping_file_location, model_args)\n\n        self.vanilla = VLSTM(\"gen-van-lstm\", mapping_file_location, model_args, dataset.TEXT)\n\n        self.max_sent_len = dataset.max_sent_len\n        UNK_IDX = dataset.TEXT.vocab.stoi[dataset.TEXT.unk_token]\n        PAD_IDX = dataset.TEXT.vocab.stoi[dataset.TEXT.pad_token]\n        self.input_size = len(dataset.TEXT.vocab)\n        self.embedding = nn.Embedding(self.input_size, model_args[\"emb_dim\"], padding_idx=PAD_IDX)\n        self.embedding.weight.data.copy_(dataset.TEXT.vocab.vectors)\n        self.embedding.weight.data[UNK_IDX] = torch.zeros(model_args[\"emb_dim\"])\n        self.embedding.weight.data[PAD_IDX] = torch.zeros(model_args[\"emb_dim\"])\n\n        self.emb_dim = model_args[\"emb_dim\"]\n        self.gen = nn.LSTM(model_args[\"emb_dim\"], \n                           model_args[\"hidden_dim\"], \n                           num_layers=model_args[\"n_layers\"], \n                           bidirectional=True,\n                           dropout=model_args[\"dropout\"])\n\n        self.fc = nn.Linear(model_args[\"hidden_dim\"] * 2, model_args[\"output_dim\"]).to(self.device)\n\n        self.lin = nn.Linear(model_args[\"emb_dim\"], model_args[\"hidden_dim\"]).to(self.device)\n\n        self.dictionaries = explanations.get_dict()\n\n        self.gen_lin, self.gen_softmax, self.explanations, self.aggregations = [], [], [], []\n        for class_label in self.dictionaries.keys():\n            dictionary = self.dictionaries[class_label]\n            stoi_expl = self.__pad([\n                torch.tensor([dataset.TEXT.vocab.stoi[word] for word in phrase.split()]).to(self.device)\n                for phrase in dictionary.keys()], explanations.max_words)\n            \n            self.gen_lin.append(nn.Linear(model_args[\"hidden_dim\"], len(stoi_expl)).to(self.device))\n            self.gen_softmax.append(nn.Softmax(2))\n            self.explanations.append(stoi_expl)#TODO\n            self.aggregations.append(nn.Conv1d(in_channels=self.max_sent_len, out_channels=1, kernel_size=1).to(self.device))\n\n\n        self.dropout = nn.Dropout(model_args[\"dropout\"])\n\n        self.optimizer = optim.Adam(self.parameters())\n        self.criterion = nn.BCEWithLogitsLoss().to(self.device)\n\n        self = self.to(self.device)\n        super().save_model_type(self)\n\n    def __pad(self, tensor_list, length):\n        \"\"\"\n        0 pad to the right for a list of variable sized tensors\n        e.g. [torch.tensor([1,2]), torch.tensor([1,2,3,4]),torch.tensor([1,2,3,4,5])], 5 ->\n                [tensor([1, 2, 0, 0, 0]), tensor([1, 2, 3, 4, 0]), tensor([1, 2, 3, 4, 5])]\n        \"\"\"\n        return torch.stack([torch.cat([tensor, tensor.new(5-tensor.size(0)).zero_()])\n            for tensor in tensor_list]).to(self.device)\n\n    def forward(self, text, text_lengths):\n        \n        batch_size = text.size()[1]\n        \n        #text = [sent len, batch size]\n        \n        embedded = self.dropout(self.embedding(text))\n        \n        #embedded = [sent len, batch size, emb dim]\n        \n        ##GEN\n        # # [sent len, batch, 2*hidden_dim]\n        # expl_activ, (_, _) = self.gen(embedded)\n        # expl_activ = nn.Dropout(0.4)(expl_activ)\n        # [sent, batch, hidden]\n        expl_activ = self.lin(embedded)\n        # expl_activ = nn.Dropout(0.4)(expl_activ)\n\n\n\n\n        context_vector, final_dict, expl_distributions = [], [], []\n\n\n\n        for i in range(len(self.dictionaries.keys())):\n            # explanations[i] -> [dict_size, max_words, emb_dim]\n\n            # [dict_size, max_words, emb_dim]\n            v_emb = self.embedding(self.explanations[i])\n\n            #[batch,dict_size, max_words, emd_dim]\n            vocab_emb = v_emb.repeat(batch_size,1,1,1)\n            #[batch,dict_size, max_words* emd_dim]\n            vocab_emb = vocab_emb.reshape(vocab_emb.size(0),vocab_emb.size(1),-1)\n\n            # [sent, batch, dict_size]\n            lin_activ = self.gen_lin[i](expl_activ)\n            # expl_activ = nn.Dropout(0.2)(lin_activ)\n            # [sent, batch, dict_size]\n            expl_dist = self.gen_softmax[i](lin_activ)\n            \n            # [batch, sent, dict_size]\n            expl_distribution = torch.transpose(expl_dist, 0, 1)\n\n            # [batch, max_sent, dict_size] (pad right)\n            size1, size2, size3 = expl_distribution.shape[0], expl_distribution.shape[1], expl_distribution.shape[2]\n            if self.max_sent_len>=size2:\n                # 0-padding\n                expl_distribution = torch.cat([expl_distribution, expl_distribution.new(size1, self.max_sent_len-size2, size3).zero_()],1).to(self.device)\n            else:\n                # trimming\n                expl_distribution = expl_distribution[:,:self.max_sent_len,:]\n            # [batch,1,dict_size]\n            expl_distribution = self.aggregations[i](expl_distribution)\n\n            # [batch,sent, max_words*emb_dim]\n            expl = torch.bmm(expl_distribution, vocab_emb)\n\n            # [batch,dict_size]\n            expl_distributions.append(expl_distribution.squeeze(1))\n\n            #[batch,max_words,emb_dim]\n            context_vector.append(torch.max(expl, dim=1).values.reshape(batch_size, v_emb.size(1),-1))\n\n\n            sep = torch.rand((batch_size,1,self.emb_dim), device=self.device)\n            # [batch, 1+1, emb_dim]\n            final_dict.append(torch.cat((sep, context_vector[i]), 1))\n\n\n        final_expl = final_dict[0]\n        for i in range(1, len(final_dict)):\n            final_expl = torch.cat((final_expl, final_dict[i]), 1)\n\n        #[batch, sent, emb]\n        x = torch.transpose(embedded,0,1)\n\n        # [batch, sent_len+2, emb_dim]\n        concat_input = torch.cat((x,final_expl),1) \n\n        #[sent_len+1, batch, emb_dim]\n        final_input = torch.transpose(concat_input,0,1)\n        \n        output = self.vanilla.raw_forward(final_input, text_lengths)\n        \n\n        #output = [sent len, batch size, hid dim * num directions]\n        #output over padding tokens are zero tensors\n        \n        #hidden = [num layers * num directions, batch size, hid dim]\n        #cell = [num layers * num directions, batch size, hid dim]\n        \n        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n        #and apply dropout\n        \n        # hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n                \n        #hidden = [batch size, hid dim * num directions]\n        self.expl_distributions = expl_distributions  \n        return output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Main"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import argparse\nfrom datetime import datetime\n\n\nstart = datetime.now()\nformated_date = start.strftime(DATE_FORMAT)\n\n\n# parser = argparse.ArgumentParser(description='Config params.')\n# parser.add_argument('-e', metavar='epochs', type=int, default=CONFIG[\"epochs\"],\n#                     help='Number of epochs')\n\n# parser.add_argument('--td', type=bool, default=CONFIG[\"toy_data\"],\n#                     help='Toy data (load just a small data subset)')\n\n# parser.add_argument('--train', dest='train', action='store_true')\n# parser.add_argument('--no_train', dest='train', action='store_false')\n# parser.set_defaults(train=CONFIG[\"train\"])\n\n# parser.add_argument('--restore', dest='restore', action='store_true')\n# parser.set_defaults(restore=CONFIG[\"restore_checkpoint\"])\n\n# parser.add_argument('--cuda', type=bool, default=CONFIG[\"cuda\"])\n# args = parser.parse_args()\n\nexperiment = Experiment(f\"e-v-{formated_date}\").with_config(CONFIG).override({\n\t\"hidden_dim\": 256,\n\t\"n_layers\": 2,\n\t\"max_dict\": 300, \n\t\"cuda\": True,\n  \"restore_checkpoint\" : False,\n  \"train\": CONFIG[\"train\"],\n  \"toy_data\": False,\t\n\t\"epochs\": CONFIG[\"epochs\"],\n\t})\n\ndataset = IMDBDataset(experiment.config)\nexplanations = RakePerClassExplanations(\"rake-per-class-300\", dataset, experiment.config)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\nformated_date = start.strftime(DATE_FORMAT)\n\nmodel = MLPGen(\"mlp-gen_vanilla-bi-lstm_mixed-expl\", MODEL_MAPPING, experiment.config, dataset, explanations)\n# model = vanilla.LSTM(\"v-lstm\", MODEL_MAPPING, experiment.config, dataset.TEXT)\nexperiment.with_data(dataset).with_dictionary(explanations).with_model(model).run()\n\nprint(f\"Time: {str(datetime.now()-start)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\n# model = MLPGen(\"mlp-gen_vanilla-bi-lstm_mixed-expl\", MODEL_MAPPING, experiment.config, dataset, explanations)\nmodel = VLSTM(\"v-lstm\", MODEL_MAPPING, experiment.config, dataset.TEXT)\nexperiment.with_data(dataset).with_dictionary(explanations).with_model(model).run()\n\nprint(f\"Time: {str(datetime.now()-start)}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}